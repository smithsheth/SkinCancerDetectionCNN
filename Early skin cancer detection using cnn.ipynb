{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "25ed37cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77072690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7d3a944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir= '/Users/Smit/jupyterfiles/skincancer'\n",
    "\n",
    "train_dir=os.path.join(base_dir, 'train')\n",
    "test_dir=os.path.join (base_dir, 'test')\n",
    "\n",
    "benign_train_dir= os.path.join(train_dir,'benign')\n",
    "malignant_train_dir= os.path.join(train_dir,'malignant') \n",
    "\n",
    "benign_val_dir = os.path.join(test_dir, 'benign') \n",
    "malignant_val_dir = os.path.join(test_dir, 'malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "64b9a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training Benign keratosis images: 115\n",
      "total training melanoma images: 115\n",
      "total val Benign keratosis images: 25\n",
      "total val melonama images: 25\n",
      "---\n",
      "Total training images: 230\n",
      "Total validation images: 50\n"
     ]
    }
   ],
   "source": [
    "num_benign_train_dir= len(os.listdir(benign_train_dir))\n",
    "num_malignant_train_dir= len(os.listdir(malignant_train_dir))\n",
    "\n",
    "num_benign_val_dir= len(os.listdir(benign_val_dir))\n",
    "num_malignant_val_dir = len(os.listdir(malignant_val_dir))\n",
    "\n",
    "total_train = num_benign_train_dir + num_malignant_train_dir \n",
    "total_val= num_benign_val_dir + num_malignant_val_dir  \n",
    "\n",
    "print('total training Benign keratosis images:', num_benign_train_dir) \n",
    "print('total training melanoma images:', num_malignant_train_dir)\n",
    " \n",
    "print('total val Benign keratosis images:', num_benign_val_dir)\n",
    "print('total val melonama images:', num_malignant_val_dir) \n",
    "\n",
    "print(\"---\")\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "69f8bf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.ImageDataGenerator object at 0x00000211A0D23D00>\n"
     ]
    }
   ],
   "source": [
    "train_image_generator=ImageDataGenerator(rescale=1./255,\n",
    "                                         rotation_range=45,\n",
    "                                         width_shift_range=.15,\n",
    "                                         height_shift_range=.15,\n",
    "                                         zoom_range=0.5,\n",
    "                                         horizontal_flip= True,\n",
    "                                         vertical_flip= True)\n",
    "print(train_image_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "12c2dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_image_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "21421098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 230 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen=train_image_generator.flow_from_directory(batch_size=3,\n",
    "                                                         directory=train_dir,\n",
    "                                                         shuffle= True,\n",
    "                                                         target_size=(150,150),\n",
    "                                                         class_mode='binary',\n",
    "                                                         color_mode='rgb')\n",
    "val_data_gen=validation_image_generator.flow_from_directory(batch_size=3,\n",
    "                                                         directory=test_dir,\n",
    "                                                         target_size=(150,150),\n",
    "                                                         class_mode='binary',\n",
    "                                                         color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d650fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classLabel(source=None):\n",
    "    \n",
    "#     datagen=ImageDataGenerator (rescale=1. / 255)\n",
    "#     data_generator =datagen.flow_from_directory(source)\n",
    "#     class_dictionary =data_generator.class_indices\n",
    "#     return data_generator, class_dictionary\n",
    "\n",
    "# labels = classLabel(train_dir)\n",
    "# print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fab8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = to_categorical(train_data_gen, num_classes= 2)\n",
    "val_data_gen = to_categorical(val_data_gen, num_classes= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, _ = next(train_data_gen)\n",
    "\n",
    "def plotImages(images_arr):\n",
    "    \n",
    "    fig, axes = plt.subplots (1, 2, figsize=(20,20)) \n",
    "    for img, ax in zip( images_arr, axes): \n",
    "        ax.imshow(img)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plotImages(sample_training_images[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34acb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, 3, padding='same', activation='relu', input_shape=(150,150,3,)))\n",
    "model.add (MaxPooling2D (pool_size=2))\n",
    "model.add (Dropout(0.25))\n",
    "\n",
    "model.add (Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add (MaxPooling2D (pool_size=2))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add (Dense (128, activation='relu'))\n",
    "\n",
    "model.add (Dense(2, activation='softmax'))\n",
    "model.compile(optimizer = 'adam',\n",
    "               loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "                  train_data_gen,\n",
    "                  validation_data= val_data_gen,\n",
    "validation_split=0.2,\n",
    "                  steps_per_epoch=len(train_data_gen),\n",
    "                  epochs=20,\n",
    "                  validation_steps = len(val_data_gen),\n",
    "                  verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history [ 'val_accuracy'] \n",
    "val_loss= history.history['val_loss']\n",
    "loss= history.history['loss']\n",
    "\n",
    "epochs = range (len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='validation accuracy')\n",
    "plt.title('Training and validation accuracy')    \n",
    "plt.legend(loc=8)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(val_data_gen,train_data_gen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc= model.evaluate_generator(val_data_gen) [1]\n",
    "print (f\"the accuracy of our model is {acc*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28184797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(val_data_gen.classes, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "img_path = \"/Users/Smit/jupyterfiles/skincancer/test/malignant/1401.jpg\"\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img_array = image.img_to_array(img)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)\n",
    "prediction = model.predict(img_batch)\n",
    "classes=  np.argmax(prediction)\n",
    "\n",
    "\n",
    "    \n",
    "if (classes == 0):\n",
    "    prediction = \"benign\"\n",
    "    print(\"No cancer\")\n",
    "else:\n",
    "    prediction = \"malignant\"\n",
    "    print(\"Yes cancer\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb191fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
